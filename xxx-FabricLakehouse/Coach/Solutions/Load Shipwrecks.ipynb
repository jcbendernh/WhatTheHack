{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fe0709-c4e4-47f4-968e-4f3fa0b1ec82",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Load Western Australia Shipwreck Data\n",
    "Loads WAM-002 Shipwrecks from https://catalogue.data.wa.gov.au/dataset/shipwrecks\n",
    "[Direct Link](https://data-downloads.slip.wa.gov.au/WAM-002/GeoJSON) and enriches with BOM Marine Zones IDM000003 http://reg.bom.gov.au/catalogue/spatialdata.pdf\n",
    "\n",
    "WAM-002 requires a free SLIP account.\n",
    "CC BY 4.0 \n",
    "\n",
    "BOM Marine Zones are available by anonymous FTP. http://www.bom.gov.au/catalogue/data-feeds.shtml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3801aeac-7392-4895-8a5b-28cf1377243d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Add geopandas to workspace libs from PyPI to run this from a pipeline (pipelines do not support pip / conda installs), \n",
    "#\n",
    "#For interactive / notebook development use:\n",
    "#%pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b6d27-9b25-41c8-99f6-bc307e41d6f2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests, json, zipfile, pathlib, urllib\n",
    "from re import sub\n",
    "\n",
    "def downloadSLIPFile(slipPath, slipFile, saveFolder, userId, password) :\n",
    "    \"\"\"\n",
    "    Downloads a file from West Australian government Shared Location Information Platform (SLIP)\n",
    "\n",
    "    Code based on https://toolkit.data.wa.gov.au/hc/en-gb/articles/115000962734 \n",
    "    \"\"\"\n",
    "\n",
    "    saveFile = f\"{saveFolder}/{slipFile}\"\n",
    "    pathlib.Path(saveFolder).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    dataDownloadRequestUrl = \"https://direct-download.slip.wa.gov.au/datadownload/{0}/{1}\".format(slipPath, slipFile)\n",
    "\n",
    "\n",
    "    tokenRequestUrl = \"https://sso.slip.wa.gov.au/as/token.oauth2\"\n",
    "    tokenRequestHeaders = { 'Authorization' : 'Basic ZGlyZWN0LWRvd25sb2Fk'}\n",
    "    tokenRequestForm={\"grant_type\": \"password\", \"username\":userId, \"password\":password}\n",
    "    tokenResponse = requests.post(tokenRequestUrl, data=tokenRequestForm, headers=tokenRequestHeaders)\n",
    "    accessToken=json.loads(tokenResponse.text)[\"access_token\"]\n",
    "\n",
    "    if tokenResponse.status_code == 200:\n",
    "        print(f\"Downloading file from URL: {dataDownloadRequestUrl} to {saveFolder}\")\n",
    "        dataDownloadRequestHeaders = { 'Authorization' : 'Bearer ' + accessToken}\n",
    "        dataDownloadResponse = requests.get(dataDownloadRequestUrl, headers=dataDownloadRequestHeaders)\n",
    "        if dataDownloadResponse.status_code == 200:\n",
    "            with open(saveFile, 'wb') as f:\n",
    "                f.write(dataDownloadResponse.content)\n",
    "            \n",
    "            with zipfile.ZipFile(saveFile, 'r') as zipref:\n",
    "                geojsonfile=[filename for filename in zipref.namelist() if filename.endswith('.geojson')][0]\n",
    "                zipref.extractall(saveFolder)\n",
    "                return f\"{saveFolder}/{geojsonfile}\"\n",
    "        else:\n",
    "            print(\"Error download file with error \" + str(dataDownloadResponse.status_code) + \"-\" + dataDownloadResponse.text)\n",
    "    else:\n",
    "        print(\"Error getting token: \" + str(tokenResponse.status_code) + \"-\" + tokenResponse.text)\n",
    "\n",
    "\n",
    "\n",
    "def downloadBOMFile(BOMServerPath, BOMServerFile, DownloadFolder):\n",
    "    \"\"\"\n",
    "    Download a file from the Australian Bureau of Meterology anonymous FTP server\n",
    "    \"\"\"\n",
    "\n",
    "    saveFile = f\"{DownloadFolder}/{BOMServerFile}\"\n",
    "    pathlib.Path(DownloadFolder).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    url = f\" ftp://anonymous@ftp.bom.gov.au{BOMServerPath}/{BOMServerFile}\"\n",
    "    print(f\"Downloading file from URL: {url} to {DownloadFolder}\")\n",
    "    urllib.request.urlretrieve(url,saveFile)\n",
    "\n",
    "    with zipfile.ZipFile(saveFile, 'r') as zipref:\n",
    "        shpfile=[filename for filename in zipref.namelist() if filename.endswith('.shp')][0]\n",
    "        zipref.extractall(DownloadFolder)\n",
    "        return f\"{DownloadFolder}/{shpfile}\"\n",
    "\n",
    "\n",
    "def toPascalCase(s):\n",
    "    \"\"\"Function to PascalCase strings.\"\"\"\n",
    "    s = sub(r\"(_|-)+\", \" \", s).title().replace(\" \", \"\").replace(\"*\",\"\")\n",
    "    return ''.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea53b8-5171-4682-ab6e-89680522015b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")\n",
    "spark.conf.set(\"sprk.sql.parquet.vorder.enabled\", \"true\") # Enable VOrder write\n",
    "spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\") # Enable automatic delta optimized write\n",
    "\n",
    "# SLIP username and password\n",
    "# Storing creds in a notebook is never a good idea, use Key Vault\n",
    "# mssparkutils.credentials.getSecret('https://SomeKeyVault.vault.azure.net/','SomeSecret')\n",
    "#\n",
    "# https://learn.microsoft.com/en-us/azure/synapse-analytics/spark/microsoft-spark-utilities?pivots=programming-language-python\n",
    "\n",
    "SLIPUsername = \"\"\n",
    "SLIPPassword = \"\"\n",
    "\n",
    "#The WAM-002 Shipwrecks data\n",
    "#https://direct-download.slip.wa.gov.au/datadownload/People_and_Society/Shipwrecks_WAM_002_WA_GDA94_Public_GeoJSON.zip\n",
    "SLIPFolder=\"People_and_Society\"\n",
    "SLIPFile=\"Shipwrecks_WAM_002_WA_GDA94_Public_GeoJSON.zip\"\n",
    "WAMsaveFolder = \"/lakehouse/default/Files/WAM\"\n",
    "\n",
    "#BOM IDM000003 - marine forecast zones\n",
    "#see http://www.bom.gov.au/catalogue/data-feeds.shtml\n",
    "BOMFolder = \"/anon/home/adfd/spatial\"\n",
    "BOMFile = \"IDM00003.zip\"\n",
    "BOMsaveFolder = \"/lakehouse/default/Files/BOM/IDM000003\"\n",
    "\n",
    "#Download files\n",
    "shipwrecks = downloadSLIPFile(SLIPFolder, SLIPFile, WAMsaveFolder, SLIPUsername, SLIPPassword)\n",
    "marineZones = downloadBOMFile(BOMFolder, BOMFile, BOMsaveFolder)\n",
    "\n",
    "#Read files, normalise CRS\n",
    "df_shipwrecks = gp.read_file(shipwrecks)\n",
    "df_marineZones = gp.read_file(marineZones).to_crs(df_shipwrecks.crs)\n",
    "\n",
    "#Filter / clean\n",
    "df_marineZones = df_marineZones[df_marineZones.STATE_CODE == \"WA\"]\n",
    "df_marineZones = df_marineZones.where(df_marineZones.notna(), None)\n",
    "\n",
    "\n",
    "#Spatial Join shipwrecks and marine zones\n",
    "df_joined = df_shipwrecks.sjoin(df_marineZones, how=\"left\", predicate='intersects')\n",
    "\n",
    "#Clean up results\n",
    "df_joined.rename(columns=lambda x: toPascalCase(x), inplace=True)\n",
    "df_joined.drop(columns={'Geometry','DistNo','StateCode','Type', 'DateDepth','TimeDepth','MaxDepth','MinDepth','BearingTo','LengthOf','ObjectId','UniqueNum', 'IndexRight', 'Pt1Name','Pt2Name'}, inplace=True)\n",
    "df_joined.rename(columns={'TypeOfSi': 'Type', 'DateInspe': 'DateInspected', 'Aac': 'AAC'}, inplace=True)\n",
    "df_joined = df_joined.where(df_joined.notna(), None)\n",
    "\n",
    "#Save to Lakehouse\n",
    "saveTable = \"Shipwrecks\"\n",
    "spark.createDataFrame(df_joined).write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").format(\"delta\").save(f\"Tables/{saveTable}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "notebook_environment": {},
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {},
    "enableDebugMode": false
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
